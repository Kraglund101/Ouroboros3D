name: o3d_shared_with_pt
tags: ["o3d"]
description: "Using shared noise_with_pt"
version: 'svd_lgm+multi-t2iadapter-rgb-ccm+plucker-o3d-shared-with-pt'
output_dir: "outputs/${name}"

extras:
  resolution: 512
  bg_color: white
  root_dir: data
  meta_file: meta.json
  ids_file_train: data/render-o3d-train.txt
  ids_file_val: data/render-o3d-val.txt
  num_frames: 4
  video_frames: 8

seed: 42
#42 works

data:
  _target_: src.data.multiview_blender.MultiViewDataModule
  train_dataset:
    _target_: src.data.multiview_blender.MultiViewDataset
    root_dir: ${extras.root_dir}/train
    meta_file: ${extras.meta_file}
    bg_color: ${extras.bg_color}
    num_frames: ${extras.video_frames}
    ids_file: ${extras.ids_file_train}
    img_wh: 
      - ${extras.resolution}
      - ${extras.resolution}
    repeat: 1
    num_samples: 5000
  train_batch_size: 1

  val_dataset:
    _target_: src.data.multiview_blender.MultiViewDataset
    root_dir: ${extras.root_dir}/val
    meta_file: ${extras.meta_file}
    bg_color: ${extras.bg_color}
    num_frames: ${extras.video_frames}
    ids_file: ${extras.ids_file_val}
    img_wh: 
      - ${extras.resolution}
      - ${extras.resolution}
    repeat: 1
    num_samples: 8
  val_batch_size: 1


  num_workers: 0
  pin_memory: False

system:
  _target_: src.systems.mv_diffusion.svd_lgm_multi_t2iadapter.SVDSystem
  lr: 1.0e-5
  base_model_id: stabilityai/stable-video-diffusion-img2vid
  recon_model_path: pretrain/LGM/model_fp16.safetensors
  variant: fp16
  cfg: 0.1
  noise_mode: shared

  mv_model:
    _target_: src.models.unet.mv_unet.MVModel
    cond_encoder:
      - _target_: src.models.unet.adaptor.Adapter_XL
        cin: 192
        channels: [320, 640, 1280, 1280]
        sk: True
        use_conv: False
        ksize: 1
      - _target_: src.models.unet.adaptor.Adapter_XL
        cin: 192
        channels: [320, 640, 1280, 1280]
        sk: True
        use_conv: False
        ksize: 1
    add_plucker: True
    _partial_: True

  recon_model:
    _target_: src.models.network.lgm.models.LGM
    num_frames: ${extras.num_frames}
    opt:
      _target_: src.models.network.lgm.options.Options
      input_size: 256
      up_channels: [1024, 1024, 512, 256, 128]
      up_attention: [True, True, True, False, False]
      splat_size: 128
      output_size: 512
      batch_size: 1
      num_views: 8
      gradient_accumulation_steps: 1
      mixed_precision: fp16

trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${output_dir}
  max_steps: 5000
  val_check_interval: 250
  accumulate_grad_batches: 1
  log_every_n_steps: 10
  num_sanity_val_steps: 0
  enable_progress_bar: true
  #strategy: auto
    #_target_: lightning.pytorch.strategies.DDPStrategy       #USED FOR DEBUG
    #find_unused_parameters: False
    
  strategy: #when it actually works i think
    _target_: lightning.pytorch.strategies.DeepSpeedStrategy
    config: config.json
  devices: 1
  num_nodes: 1
  precision: 16-mixed
  gradient_clip_val: 1

callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    save_top_k: 1
    every_n_train_steps: 1000
    dirpath: "${output_dir}/${version}/checkpoints"

logger:
  tensorboard:
    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    save_dir: "${output_dir}"
    name: ""
    version: "${version}"
    sub_dir: "tb_logs"


#s√¶t over med med pretraining alle versioner i morgen